{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4371445d",
   "metadata": {},
   "source": [
    "# Sonar System Object Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ce8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulate data\n",
    "using CSV \n",
    "using DataFrames\n",
    "# Data exploration and visualization\n",
    "using PrettyPrinting\n",
    "import Statistics\n",
    "# Create pseudo-random numbers\n",
    "using StableRNGs\n",
    "\n",
    "### Machine Learning Framework ### \n",
    "using MLJ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b92c5b",
   "metadata": {},
   "source": [
    "## 0. The Problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d6cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6fe9620",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898397fc",
   "metadata": {},
   "source": [
    "### 1.2 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821715b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 61 columns (omitted printing of 52 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>0.0200</th><th>0.0371</th><th>0.0428</th><th>0.0207</th><th>0.0954</th><th>0.0986</th><th>0.1539</th><th>0.1601</th><th>0.3109</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.0453</td><td>0.0523</td><td>0.0843</td><td>0.0689</td><td>0.1183</td><td>0.2583</td><td>0.2156</td><td>0.3481</td><td>0.3337</td></tr><tr><th>2</th><td>0.0262</td><td>0.0582</td><td>0.1099</td><td>0.1083</td><td>0.0974</td><td>0.228</td><td>0.2431</td><td>0.3771</td><td>0.5598</td></tr><tr><th>3</th><td>0.01</td><td>0.0171</td><td>0.0623</td><td>0.0205</td><td>0.0205</td><td>0.0368</td><td>0.1098</td><td>0.1276</td><td>0.0598</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& 0.0200 & 0.0371 & 0.0428 & 0.0207 & 0.0954 & 0.0986 & 0.1539 & 0.1601 & 0.3109 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0.0453 & 0.0523 & 0.0843 & 0.0689 & 0.1183 & 0.2583 & 0.2156 & 0.3481 & 0.3337 & $\\dots$ \\\\\n",
       "\t2 & 0.0262 & 0.0582 & 0.1099 & 0.1083 & 0.0974 & 0.228 & 0.2431 & 0.3771 & 0.5598 & $\\dots$ \\\\\n",
       "\t3 & 0.01 & 0.0171 & 0.0623 & 0.0205 & 0.0205 & 0.0368 & 0.1098 & 0.1276 & 0.0598 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×61 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m 0.0200  \u001b[0m\u001b[1m 0.0371  \u001b[0m\u001b[1m 0.0428  \u001b[0m\u001b[1m 0.0207  \u001b[0m\u001b[1m 0.0954  \u001b[0m\u001b[1m 0.0986  \u001b[0m\u001b[1m 0.1539  \u001b[0m\u001b[1m 0.1601  \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │  0.0453   0.0523   0.0843   0.0689   0.1183   0.2583   0.2156   0.3481  ⋯\n",
       "   2 │  0.0262   0.0582   0.1099   0.1083   0.0974   0.228    0.2431   0.3771\n",
       "   3 │  0.01     0.0171   0.0623   0.0205   0.0205   0.0368   0.1098   0.1276\n",
       "\u001b[36m                                                              53 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "df = CSV.read(\"sonar.csv\",DataFrame)\n",
    "first(df,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03c828",
   "metadata": {},
   "source": [
    "Note that there are many columns hidden and As we can see, the dataframe does not have a header, so we must built it and load again the data. The first \n",
    "columns represent signals (amount of energy) captured by the Sonar, each one in a specific frequency, the last column apparently contains the category labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "534accb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 8 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>Freq54</th><th>Freq55</th><th>Freq56</th><th>Freq57</th><th>Freq58</th><th>Freq59</th><th>Freq60</th><th>Label</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"String1\">String1</th></tr></thead><tbody><tr><th>1</th><td>0.0159</td><td>0.0072</td><td>0.0167</td><td>0.018</td><td>0.0084</td><td>0.009</td><td>0.0032</td><td>R</td></tr><tr><th>2</th><td>0.0048</td><td>0.0094</td><td>0.0191</td><td>0.014</td><td>0.0049</td><td>0.0052</td><td>0.0044</td><td>R</td></tr><tr><th>3</th><td>0.0095</td><td>0.018</td><td>0.0244</td><td>0.0316</td><td>0.0164</td><td>0.0095</td><td>0.0078</td><td>R</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& Freq54 & Freq55 & Freq56 & Freq57 & Freq58 & Freq59 & Freq60 & Label\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & String1\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.0159 & 0.0072 & 0.0167 & 0.018 & 0.0084 & 0.009 & 0.0032 & R \\\\\n",
       "\t2 & 0.0048 & 0.0094 & 0.0191 & 0.014 & 0.0049 & 0.0052 & 0.0044 & R \\\\\n",
       "\t3 & 0.0095 & 0.018 & 0.0244 & 0.0316 & 0.0164 & 0.0095 & 0.0078 & R \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×8 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Freq54  \u001b[0m\u001b[1m Freq55  \u001b[0m\u001b[1m Freq56  \u001b[0m\u001b[1m Freq57  \u001b[0m\u001b[1m Freq58  \u001b[0m\u001b[1m Freq59  \u001b[0m\u001b[1m Freq60  \u001b[0m\u001b[1m Label   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String1 \u001b[0m\n",
       "─────┼────────────────────────────────────────────────────────────────────────\n",
       "   1 │  0.0159   0.0072   0.0167   0.018    0.0084   0.009    0.0032  R\n",
       "   2 │  0.0048   0.0094   0.0191   0.014    0.0049   0.0052   0.0044  R\n",
       "   3 │  0.0095   0.018    0.0244   0.0316   0.0164   0.0095   0.0078  R"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the header with a list\n",
    "header = [\"Freq$i\" for i=1:size(df,2)-1 ]\n",
    "push!(header,\"Label\")\n",
    "# Re Load data and set header\n",
    "df = CSV.read(\"sonar.csv\",DataFrame,header=header)\n",
    "\n",
    "# Watch last 7 columns and first 3 rows\n",
    "first(select(df, 54:61 ),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87bc90b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the DataFrame (cols,rows): \t (208, 61) \n",
      "    \n",
      "Data Type/Format of the first 60 columns: \t Float64 \n",
      "    \n",
      "Data Type/Format of the last column: \t \t String1"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of the DataFrame (cols,rows): \\t $(size(df)) \n",
    "    \\nData Type/Format of the first $(size(df,2)-1) columns: \\t $(typeof(df[1,1])) \n",
    "    \\nData Type/Format of the last column: \\t \\t $(typeof(df[1,end]))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763678df",
   "metadata": {},
   "source": [
    "So we have $N=208$ samples, and the dimension of the feature vector is $D=60$. Next, we are obtaining the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4acd9b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>8 rows × 7 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th title=\"Symbol\">Symbol</th><th title=\"Union{Nothing, Float64}\">Union…</th><th title=\"Any\">Any</th><th title=\"Union{Nothing, Float64}\">Union…</th><th title=\"Any\">Any</th><th title=\"Int64\">Int64</th><th title=\"DataType\">DataType</th></tr></thead><tbody><tr><th>1</th><td>Freq54</td><td>0.0109409</td><td>0.001</td><td>0.0093</td><td>0.0352</td><td>0</td><td>Float64</td></tr><tr><th>2</th><td>Freq55</td><td>0.00929038</td><td>0.0006</td><td>0.0075</td><td>0.0447</td><td>0</td><td>Float64</td></tr><tr><th>3</th><td>Freq56</td><td>0.00822163</td><td>0.0004</td><td>0.00685</td><td>0.0394</td><td>0</td><td>Float64</td></tr><tr><th>4</th><td>Freq57</td><td>0.00782019</td><td>0.0003</td><td>0.00595</td><td>0.0355</td><td>0</td><td>Float64</td></tr><tr><th>5</th><td>Freq58</td><td>0.00794904</td><td>0.0003</td><td>0.0058</td><td>0.044</td><td>0</td><td>Float64</td></tr><tr><th>6</th><td>Freq59</td><td>0.00794135</td><td>0.0001</td><td>0.0064</td><td>0.0364</td><td>0</td><td>Float64</td></tr><tr><th>7</th><td>Freq60</td><td>0.00650721</td><td>0.0006</td><td>0.0053</td><td>0.0439</td><td>0</td><td>Float64</td></tr><tr><th>8</th><td>Label</td><td></td><td>M</td><td></td><td>R</td><td>0</td><td>String1</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & Freq54 & 0.0109409 & 0.001 & 0.0093 & 0.0352 & 0 & Float64 \\\\\n",
       "\t2 & Freq55 & 0.00929038 & 0.0006 & 0.0075 & 0.0447 & 0 & Float64 \\\\\n",
       "\t3 & Freq56 & 0.00822163 & 0.0004 & 0.00685 & 0.0394 & 0 & Float64 \\\\\n",
       "\t4 & Freq57 & 0.00782019 & 0.0003 & 0.00595 & 0.0355 & 0 & Float64 \\\\\n",
       "\t5 & Freq58 & 0.00794904 & 0.0003 & 0.0058 & 0.044 & 0 & Float64 \\\\\n",
       "\t6 & Freq59 & 0.00794135 & 0.0001 & 0.0064 & 0.0364 & 0 & Float64 \\\\\n",
       "\t7 & Freq60 & 0.00650721 & 0.0006 & 0.0053 & 0.0439 & 0 & Float64 \\\\\n",
       "\t8 & Label &  & M &  & R & 0 & String1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m8×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable \u001b[0m\u001b[1m mean       \u001b[0m\u001b[1m min    \u001b[0m\u001b[1m median  \u001b[0m\u001b[1m max    \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol   \u001b[0m\u001b[90m Union…     \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Union…  \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m DataType \u001b[0m\n",
       "─────┼───────────────────────────────────────────────────────────────────\n",
       "   1 │ Freq54    0.0109409   0.001   0.0093   0.0352         0  Float64\n",
       "   2 │ Freq55    0.00929038  0.0006  0.0075   0.0447         0  Float64\n",
       "   3 │ Freq56    0.00822163  0.0004  0.00685  0.0394         0  Float64\n",
       "   4 │ Freq57    0.00782019  0.0003  0.00595  0.0355         0  Float64\n",
       "   5 │ Freq58    0.00794904  0.0003  0.0058   0.044          0  Float64\n",
       "   6 │ Freq59    0.00794135  0.0001  0.0064   0.0364         0  Float64\n",
       "   7 │ Freq60    0.00650721  0.0006  0.0053   0.0439         0  Float64\n",
       "   8 │ Label    \u001b[90m            \u001b[0m M      \u001b[90m         \u001b[0m R              0  String1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(select(df, 54:61))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fef016",
   "metadata": {},
   "source": [
    "Note that the labels are `M` for mines and `R` for rocks.\n",
    "\n",
    "To analyse range values in frequency columns in one shot we can: \n",
    "- make groups by  `eltype`, obtaining two groups (frequencies and target)\n",
    "- Describe the mean,min and max over mean, median, max and number of missing value in the first group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1eae18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>6 rows × 4 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>max</th></tr><tr><th></th><th title=\"Symbol\">Symbol</th><th title=\"Union{Nothing, Float64}\">Union…</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th></tr></thead><tbody><tr><th>1</th><td>variable</td><td></td><td>Freq1</td><td>Freq9</td></tr><tr><th>2</th><td>mean</td><td>0.281321</td><td>0.00650721</td><td>0.702155</td></tr><tr><th>3</th><td>min</td><td>0.0189433</td><td>0.0</td><td>0.0921</td></tr><tr><th>4</th><td>max</td><td>0.655823</td><td>0.0352</td><td>1.0</td></tr><tr><th>5</th><td>nmissing</td><td>0.0</td><td>0</td><td>0</td></tr><tr><th>6</th><td>eltype</td><td></td><td></td><td></td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& variable & mean & min & max\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & variable &  & Freq1 & Freq9 \\\\\n",
       "\t2 & mean & 0.281321 & 0.00650721 & 0.702155 \\\\\n",
       "\t3 & min & 0.0189433 & 0.0 & 0.0921 \\\\\n",
       "\t4 & max & 0.655823 & 0.0352 & 1.0 \\\\\n",
       "\t5 & nmissing & 0.0 & 0 & 0 \\\\\n",
       "\t6 & eltype &  &  &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m6×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable \u001b[0m\u001b[1m mean      \u001b[0m\u001b[1m min        \u001b[0m\u001b[1m max      \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol   \u001b[0m\u001b[90m Union…    \u001b[0m\u001b[90m Any        \u001b[0m\u001b[90m Any      \u001b[0m\n",
       "─────┼───────────────────────────────────────────\n",
       "   1 │ variable \u001b[90m           \u001b[0m Freq1       Freq9\n",
       "   2 │ mean      0.281321   0.00650721  0.702155\n",
       "   3 │ min       0.0189433  0.0         0.0921\n",
       "   4 │ max       0.655823   0.0352      1.0\n",
       "   5 │ nmissing  0.0        0           0\n",
       "   6 │ eltype   \u001b[90m           \u001b[0m\u001b[90m            \u001b[0m\u001b[90m          \u001b[0m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(groupby(describe(df,:mean,:min,:max,:nmissing,:eltype),:eltype)[1], :mean,:min,:max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb302dbf",
   "metadata": {},
   "source": [
    "We can see that the values of the feature vector for each sample are small floating point numbers between 0 and 1, so it is convenient to store them as `Float64` to avoid roundoff error, also we can be sure that there aren't missing values in the whole dataset.  \n",
    "\n",
    "Lets take a look on the number of rocks and mines in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16339a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Mines (M): 111 \n",
      "Number of Rocks (R):  97"
     ]
    }
   ],
   "source": [
    "num_R = count(i->(i==\"R\"),df[:,end])\n",
    "num_M = count(i->(i==\"M\"),df[:,end])\n",
    "print(\"Number of Mines (M): $num_M \\nNumber of Rocks (R):  $num_R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4b01c8",
   "metadata": {},
   "source": [
    "As we can see, the distrbution of mines and rocks is not discrete-uniform, this is an important fact we have to consider when spliting the data into train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050b6e2",
   "metadata": {},
   "source": [
    "### 1.2 Scientific Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa7259f",
   "metadata": {},
   "source": [
    "Lets analyse how the data is interpreted, which means, the Scitype of the variables stored in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a982945f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────┬────────────┬─────────┐\n",
       "│\u001b[22m names  \u001b[0m│\u001b[22m scitypes   \u001b[0m│\u001b[22m types   \u001b[0m│\n",
       "├────────┼────────────┼─────────┤\n",
       "│ Freq54 │ Continuous │ Float64 │\n",
       "│ Freq55 │ Continuous │ Float64 │\n",
       "│ Freq56 │ Continuous │ Float64 │\n",
       "│ Freq57 │ Continuous │ Float64 │\n",
       "│ Freq58 │ Continuous │ Float64 │\n",
       "│ Freq59 │ Continuous │ Float64 │\n",
       "│ Freq60 │ Continuous │ Float64 │\n",
       "│ Label  │ Textual    │ String1 │\n",
       "└────────┴────────────┴─────────┘\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(select(df, 54:61))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7200bb83",
   "metadata": {},
   "source": [
    "The value in each cell of a Frequency column represents an amount of energy, so it is reasonable to let them be continuous Scitypes, but the Label column should be a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "841e102e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┬──────────────────┬───────────────────────────────────┐\n",
       "│\u001b[22m names \u001b[0m│\u001b[22m scitypes         \u001b[0m│\u001b[22m types                             \u001b[0m│\n",
       "├───────┼──────────────────┼───────────────────────────────────┤\n",
       "│ Label │ OrderedFactor{2} │ CategoricalValue{String1, UInt32} │\n",
       "└───────┴──────────────────┴───────────────────────────────────┘\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = coerce( df, :Label => OrderedFactor)\n",
    "schema(select(df,:Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae351d82",
   "metadata": {},
   "source": [
    "Now, the categorical labels identified are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13184fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{String1}:\n",
       " \"M\"\n",
       " \"R\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels(df.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63add9a2",
   "metadata": {},
   "source": [
    "In the model assesment it is appropiate to interpret a mine as \"positive\" and a rock as \"negative\", so we ought to define the order $R < M$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ab38344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{String1}:\n",
       " \"R\"\n",
       " \"M\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels!(df.Label, [\"R\",\"M\"])\n",
    "levels(df.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a85514c",
   "metadata": {},
   "source": [
    "One can check the order relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914c5690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category of first sample: R \n",
      "Category of last sample: M"
     ]
    }
   ],
   "source": [
    "print(\"Category of first sample: $(df.Label[1]) \\nCategory of last sample: $(df.Label[end])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5e99df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label[1]<df.Label[end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04ac4f",
   "metadata": {},
   "source": [
    "## 2. Data Set Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a0fe7",
   "metadata": {},
   "source": [
    "### 2.1 Input-Output split\n",
    "To make the input-output split (X,y structure) is very easy using the `unpack` function in the MLJ framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c81f7d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = unpack(df, ==(:Label));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f460e",
   "metadata": {},
   "source": [
    "### 2.2 Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea9309",
   "metadata": {},
   "source": [
    "We are taking 70% of the data for training and the rest for testing. Remember that the amount of rocks and mines is not the same, so we have to guarante that the proportion won't change after the set split. \n",
    "\n",
    "The split is done over the data set **indices**, this is the common way in the MLJ framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d75ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rocks indices\n",
    "rocks_idx = findall(==(\"R\"),y)\n",
    "# Get mines indices\n",
    "mines_idx = findall(==(\"M\"),y)\n",
    "\n",
    "# Set a random seed\n",
    "rng = StableRNG(0)\n",
    "# Make a random partition over mines indices \n",
    "train_mines , test_mines = partition( mines_idx , 0.7, shuffle=true, rng=rng)\n",
    "# Make a random partition over rocks indices \n",
    "train_rocks , test_rocks = partition( rocks_idx , 0.7, shuffle=true, rng=rng)\n",
    "\n",
    "# join mines and rocks (indices) for each set\n",
    "train = [train_mines ; train_rocks]\n",
    "test = [test_mines ; test_rocks];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb183ff",
   "metadata": {},
   "source": [
    "## 3. Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca77067",
   "metadata": {},
   "source": [
    "### 3.1 Available Models\n",
    "\n",
    "After preprocessing our data, especially setting the categorical variables and the other scitypes, it is possible to know which models in the MLJ framework are aproppiate for our data, considering the structure $X,y$. This can be done using the function `models` along with the function `matching`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a845e58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier            \t (ScikitLearn)\n",
      "AdaBoostStumpClassifier       \t (DecisionTree)\n",
      "BaggingClassifier             \t (ScikitLearn)\n",
      "BayesianLDA                   \t (MultivariateStats)\n",
      "BayesianLDA                   \t (ScikitLearn)\n",
      "BayesianQDA                   \t (ScikitLearn)\n",
      "BayesianSubspaceLDA           \t (MultivariateStats)\n",
      "ConstantClassifier            \t (MLJModels)\n",
      "DSADDetector                  \t (OutlierDetectionNetworks)\n",
      "DecisionTreeClassifier        \t (BetaML)\n",
      "DecisionTreeClassifier        \t (DecisionTree)\n",
      "DeterministicConstantClassifier\t (MLJModels)\n",
      "DummyClassifier               \t (ScikitLearn)\n",
      "ESADDetector                  \t (OutlierDetectionNetworks)\n",
      "EvoTreeClassifier             \t (EvoTrees)\n",
      "ExtraTreesClassifier          \t (ScikitLearn)\n",
      "GaussianNBClassifier          \t (NaiveBayes)\n",
      "GaussianNBClassifier          \t (ScikitLearn)\n",
      "GaussianProcessClassifier     \t (ScikitLearn)\n",
      "GradientBoostingClassifier    \t (ScikitLearn)\n",
      "KNNClassifier                 \t (NearestNeighborModels)\n",
      "KNeighborsClassifier          \t (ScikitLearn)\n",
      "KernelPerceptronClassifier    \t (BetaML)\n",
      "LDA                           \t (MultivariateStats)\n",
      "LGBMClassifier                \t (LightGBM)\n",
      "LinearBinaryClassifier        \t (GLM)\n",
      "LinearSVC                     \t (LIBSVM)\n",
      "LogisticCVClassifier          \t (ScikitLearn)\n",
      "LogisticClassifier            \t (MLJLinearModels)\n",
      "LogisticClassifier            \t (ScikitLearn)\n",
      "MultinomialClassifier         \t (MLJLinearModels)\n",
      "NeuralNetworkClassifier       \t (MLJFlux)\n",
      "NuSVC                         \t (LIBSVM)\n",
      "PassiveAggressiveClassifier   \t (ScikitLearn)\n",
      "PegasosClassifier             \t (BetaML)\n",
      "PerceptronClassifier          \t (BetaML)\n",
      "PerceptronClassifier          \t (ScikitLearn)\n",
      "ProbabilisticSGDClassifier    \t (ScikitLearn)\n",
      "RandomForestClassifier        \t (BetaML)\n",
      "RandomForestClassifier        \t (DecisionTree)\n",
      "RandomForestClassifier        \t (ScikitLearn)\n",
      "RidgeCVClassifier             \t (ScikitLearn)\n",
      "RidgeClassifier               \t (ScikitLearn)\n",
      "SGDClassifier                 \t (ScikitLearn)\n",
      "SVC                           \t (LIBSVM)\n",
      "SVMClassifier                 \t (ScikitLearn)\n",
      "SVMLinearClassifier           \t (ScikitLearn)\n",
      "SVMNuClassifier               \t (ScikitLearn)\n",
      "SubspaceLDA                   \t (MultivariateStats)\n",
      "XGBoostClassifier             \t (XGBoost)\n"
     ]
    }
   ],
   "source": [
    "for m in models(matching(X, y))\n",
    "    println(rpad(m.name, 30), \"\\t ($(m.package_name))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d46fb",
   "metadata": {},
   "source": [
    "As we can see, most models are implemented outside of the MLJ ecosystem; we therefore have to load models using the `@load` command and specifying the package where it comes from. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7befdfa7",
   "metadata": {},
   "source": [
    "According to the theory we have seen in the signature, the choosen models are: \n",
    "- LinearSVC (Support vector machine with linear Kernel)\n",
    "- SVC (Support vector machine with RBF kernel)\n",
    "- LogisticClassifier (Logistic regression)\n",
    "- DecisionTreeClassifier (Ordinary Desicion Tree) \n",
    "- KNeighborsClassifier (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a6c76",
   "metadata": {},
   "source": [
    "### 3.2 Single model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ceff24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJScikitLearnInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\JSeba\\.julia\\packages\\MLJModels\\OYpZv\\src\\loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticClassifier(\n",
       "    penalty = \"l2\",\n",
       "    dual = false,\n",
       "    tol = 0.0001,\n",
       "    C = 1.0,\n",
       "    fit_intercept = true,\n",
       "    intercept_scaling = 1.0,\n",
       "    class_weight = nothing,\n",
       "    random_state = nothing,\n",
       "    solver = \"lbfgs\",\n",
       "    max_iter = 100,\n",
       "    multi_class = \"auto\",\n",
       "    verbose = 0,\n",
       "    warm_start = false,\n",
       "    n_jobs = nothing,\n",
       "    l1_ratio = nothing)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the ScikitLearn ecosystem\n",
    "LogisticClassifier  = @load LogisticClassifier  pkg=ScikitLearn\n",
    "# Create a model instance with the default hyperparameters\n",
    "logistic_model = LogisticClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878c6a6",
   "metadata": {},
   "source": [
    "In MLJ, a **model** is an object that only serves as a container for the hyperparameters of the model. A **machine** is an object wrapping both a model and data and can contain information on the trained model; it does not fit the model by itself. However, it does check that the model is compatible with the scientific type of the data and will warn you otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e5da527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{LogisticClassifier,…}.\n",
      "└ @ MLJBase C:\\Users\\JSeba\\.julia\\packages\\MLJBase\\rMXo2\\src\\machines.jl:423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{LogisticClassifier,…} trained 1 time; caches data\n",
       "  model: MLJScikitLearnInterface.LogisticClassifier\n",
       "  args: \n",
       "    1:\tSource @209 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @143 ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a machine\n",
    "logistic = machine(logistic_model, X, y)\n",
    "# Train the machine\n",
    "fit!(logistic, rows=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5057bce",
   "metadata": {},
   "source": [
    "Some Classifiers, as the logistic regression work, with *Probabilistic* predictions, the output value represents the probability of $y^{i}$ being positive (1 or `M`) given $X^{(i)}$. We can get this probabilistic values with the function `prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a7a2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistic prediction given test input\n",
    "ŷ_prob = predict(logistic, rows=test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71970163",
   "metadata": {},
   "source": [
    "Also MLJ allows to show this information for one sample in a fancy way by using the  `@show` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb612272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ŷ_prob[1] = UnivariateFinite{OrderedFactor{2}}(R=>0.305, M=>0.695)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         \u001b[97;1mUnivariateFinite{OrderedFactor{2}}\u001b[0m     \n",
       "     \u001b[38;5;8m┌                                        ┐\u001b[0m \n",
       "   R \u001b[38;5;8m┤\u001b[0m\u001b[38;5;2m■■■■■■■■■\u001b[0m 0.3045705477167904            \u001b[38;5;8m \u001b[0m \u001b[38;5;8m\u001b[0m\n",
       "   M \u001b[38;5;8m┤\u001b[0m\u001b[38;5;2m■■■■■■■■■■■■■■■■■■■■\u001b[0m 0.6954294522832096 \u001b[38;5;8m \u001b[0m \u001b[38;5;8m\u001b[0m\n",
       "     \u001b[38;5;8m└                                        ┘\u001b[0m "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show ŷ_prob[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8a00a",
   "metadata": {},
   "source": [
    "To get the prediction according to the decision boundary (typically 0.5) one might use `predict_mode` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce657fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element CategoricalArrays.CategoricalArray{String1,1,UInt32}:\n",
       " \"M\"\n",
       " \"M\"\n",
       " \"M\"\n",
       " \"M\"\n",
       " \"R\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definite prediction over the test input\n",
    "ŷ = predict_mode(logistic, rows=test)\n",
    "ŷ[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0d478",
   "metadata": {},
   "source": [
    "### 3.3 Model Assesment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a0695",
   "metadata": {},
   "source": [
    "In classification problems is it always useful to compute the confussion matrix to identify paterns and understand proportions of correct classification and deviations in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08a19cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      R      │      M      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      R      │     24      │      7      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      M      │      5      │     26      │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat(ŷ,y[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6c195",
   "metadata": {},
   "source": [
    "In our case, using the Sonar System we rather to detect all the mines possible and tolerate some falsepositive rocks. So, the most suitable measure is the recall which is computed by \n",
    "$$ \\text{recall} = \\frac{TP}{TP+FN}$$\n",
    "the recall is also calle as True Positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edc65e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall in logistic regression: 0.7878787878787878"
     ]
    }
   ],
   "source": [
    "logistic_recall = recall(ŷ,y[test]);\n",
    "print(\"Recall in logistic regression: $logistic_recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06ba37c",
   "metadata": {},
   "source": [
    "### 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6746c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJLIBSVMInterface ✔\n",
      "import MLJLIBSVMInterface ✔\n",
      "import MLJScikitLearnInterface ✔\n",
      "import MLJDecisionTreeInterface ✔\n",
      "import MLJScikitLearnInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\JSeba\\.julia\\packages\\MLJModels\\OYpZv\\src\\loading.jl:168\n",
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\JSeba\\.julia\\packages\\MLJModels\\OYpZv\\src\\loading.jl:168\n",
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\JSeba\\.julia\\packages\\MLJModels\\OYpZv\\src\\loading.jl:168\n",
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\JSeba\\.julia\\packages\\MLJModels\\OYpZv\\src\\loading.jl:168\n",
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\JSeba\\.julia\\packages\\MLJModels\\OYpZv\\src\\loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLJScikitLearnInterface.KNeighborsClassifier"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all models \n",
    "Linear_SVC = @load LinearSVC\n",
    "SVC = @load SVC\n",
    "LogisticClassifier = @load LogisticClassifier pkg=ScikitLearn\n",
    "DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree\n",
    "KNeighborsClassifier = @load KNeighborsClassifier ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bfc0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Models = []"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
